lambda <- N*((i+k)^(-alpha))
list[i,2]<-rpois(1,lambda)
}
list[,3]<- lead(list[,2])
no<- subset(list[,1],list[,2]<=list[,3])[1]
no_M[m] <- no
#summarize mistakes
if (no==1){case1 <- case1+1} else {
if (list[,2][no+1]>list[,2][no] & list[,2][no-1]>list[,2][no+1]){
case1 <- case1+1
}}
if (list[,2][no+1]==list[,2][no]){
case2 <- case2+1
}
}
gen_alpha$sim_n1[j] <- quantile(no_M,0.005)
gen_alpha$sim_n2[j] <- quantile(no_M,0.01)
gen_alpha$No[j] <- sum(no_M < gen_alpha$thm_n[j])
gen_alpha$case1[j] <- case1
gen_alpha$case2[j] <- case2
}
alpha <- seq(0.1,0.95,0.05)
gen_alpha <- as.data.frame(alpha)
M <- 10000
N <- 10^7
k <- 0
gen_alpha$thm_n <- rep(0,9)
gen_alpha$sim_n1 <- rep(0,9)
gen_alpha$sim_n2 <- rep(0,9)
gen_alpha$No <- rep(0,9)
gen_alpha$case1 <- rep(0,9)
gen_alpha$case2 <- rep(0,9)
pb <- tkProgressBar("进度","已完成 %",  0, 100)
for(j in 1:18){
alpha <- gen_alpha$alpha[j]
A <- alpha^2*(alpha+2)/4
info <- sprintf("已完成 %d%%", round(j*100/18))
setTkProgressBar(pb, j*100/18, sprintf("进度 (%s)", info), info)
no_M <- rep(0,M)
case1 <-0
case2 <-0
for(m in 1:M){
list <- as.data.frame(c(1:300))
gen_alpha$thm_n[j] <- (A*N/log(N))^(1/(alpha+2))-k
for (i in 1:300){
lambda <- N*((i+k)^(-alpha))
list[i,2]<-rpois(1,lambda)
}
list[,3]<- lead(list[,2])
no<- subset(list[,1],list[,2]<=list[,3])[1]
no_M[m] <- no
#summarize mistakes
if (no==1){case1 <- case1+1} else {
if (list[,2][no+1]>list[,2][no] & list[,2][no-1]>list[,2][no+1]){
case1 <- case1+1
}}
if (list[,2][no+1]==list[,2][no]){
case2 <- case2+1
}
}
gen_alpha$sim_n1[j] <- quantile(no_M,0.005)
gen_alpha$sim_n2[j] <- quantile(no_M,0.01)
gen_alpha$No[j] <- sum(no_M < gen_alpha$thm_n[j])
gen_alpha$case1[j] <- case1
gen_alpha$case2[j] <- case2
}
close(pb)
gen_alpha$case3 <- 10^4-gen_alpha$case1-gen_alpha$case2
View(gen_alpha)
write.xlsx(generalize,file = 'F:/gen_alpha.xlsx')
save.image("C:/Users/User Soft/Desktop/论文/data/zipf.RData")
install.packages(c("acepack", "assertthat", "BH", "boot", "car", "chron", "cluster", "codetools", "colorspace", "data.table", "DBI", "DEoptimR", "DescTools", "digest", "evaluate", "expm", "foreign", "formatR", "ggplot2", "gss", "Hmisc", "htmltools", "installr", "jsonlite", "knitr", "lattice", "lme4", "lmtest", "lubridate", "markdown", "MASS", "Matrix", "mgcv", "msm", "mvtnorm", "ncdf4", "nlme", "openxlsx", "pbkrtest", "plotrix", "proto", "quantmod", "quantreg", "R.matlab", "R.oo", "R.utils", "R6", "Rcpp", "RcppArmadillo", "RcppEigen", "readxl", "reshape", "reshape2", "robustbase", "RODBC", "rpart", "RSQLite", "scales", "SparseM", "stabledist", "stringi", "stringr", "survival", "tibble", "urca", "vcd", "XML", "yaml", "zoo"))
args("rnorm")
rnorm
con <- url("http://www.jhsph.edu",r)
con <- url("http://www.jhsph.edu","r")
x <- readLines(con)
head(x)
library(ggplot2)
qplot(displ,hwy,data=mpg,geom = c("points","smooth"))
qplot(displ,hwy,data=mpg,geom = c("point","smooth"))
set.seed(1234)
par(mar=c(0,0,0,0))
x <- rnorm(12,mean=rep(1:3,each=4),sd=0.2)
y <- rnorm(12,mean = rep(c(1,2,1),each=4),sd=0.2)
plot(x,y,col="blue",pch=19,cex=2)
text(x+0.05,y+0.05,labels = as.character(1:12))
getwd()
read.csv("myfile.csv")
getwd()
install.packages("httr")
install.packages(c("backports", "devtools", "dplyr", "foreign", "jsonlite", "Matrix", "quantmod", "R6", "Rcpp", "RcppArmadillo", "tibble", "XML"))
library(httr)
pg1=GET("http://httpbin.org/basic-auth/user/passwd")
pg1
pg2=GET("http://httpbin.org/basic-auth/user/passwd",authenticate("user","passwd"))
pg2
names(pg2)
google=handle("http://google.com")
pg1=GET(handle = google,path="/")
pg2=GET(handle = google,path="search")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "dad10a356f494efd543f",
secret = "86d16a0ebbd962e58d655af284d5f143fe226d7b")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/rate_limit", gtoken)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
req <- GET("https://api.github.com/rate_limit", gtoken)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
myapp <- oauth_app("Test",
key = "dad10a356f494efd543f",
secret = "86d16a0ebbd962e58d655af284d5f143fe226d7b")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
oauth_endpoints("github")
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "dad10a356f494efd543f",
secret = "86d16a0ebbd962e58d655af284d5f143fe226d7b")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "dad10a356f494efd543f",
secret = "86d16a0ebbd962e58d655af284d5f143fe226d7b")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
library(httpuv)
library(httr)
library(httpuv)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "dad10a356f494efd543f",
secret = "86d16a0ebbd962e58d655af284d5f143fe226d7b")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
library(jsonlite)
jsondata <- fromJSON(toJSON(content(req)))
subset(jsondata, name == "datasharing", select = c(created_at))
myapp <- oauth_app("github",
key = "9ac78a3b36b3862ed435",
secret = "e1c3be242976383cc5f28dae177d41eef5445e3f")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(httr)
library(httpuv)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "dad10a356f494efd543f",
secret = "f92ce06711a7ab6ce7ef2dda5d793f8b30fa02bd")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
library(jsonlite)
jsondata <- fromJSON(toJSON(content(req)))
subset(jsondata, name == "datasharing", select = c(created_at))
library(sqldf)
acs <- read.csv(file="F:/Coursera/datasciencecoursera/Course3 Getting and Cleaning Data/Week2/acs.csv")
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
url <- url("http://biostat.jhsph.edu/~jleek/contact.html")
q4 <- readLines(url,n=100)
nchar(q4[10])
nchar(q4[20])
nchar(q4[30])
nchar(q4[100])
q5 <- read.fwf(file = "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
q5 <- read.fwf(file = "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for",
skip = 4,
widths = c(12, 7,4, 9,4, 9,4, 9,4))
View(q5)
sum(q5[,4])
set.seed(12345)
x <- data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
x <- x[sample(1:5),]
x$var2[c(1,3)] <- NA
x
x[,1]
x[,"var1"]
x[1:2,"var2"]
x[(x$var1<=3 &x$var3>11),]
x[(x$var1<=3 | x$var3>11),]
x[which(x$var2>8),]#using which command
sort(x$var1)
ort(x$var1,decreasing=TRUE)
sort(x$var1,decreasing=TRUE)
sort(x$var2,na.last = TRUE)
x[order(x$var1),]
x[order(x$var1,x$var3),]
library(plyr)
arrange(x,var1)
x
arrange(x,desc(var1))
x$var4 <- rnorm(5)
x
Y　<- cbind(x,rnorm(5))
Y
getwd()
setwd("F:/Coursera/datasciencecoursera/")
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile = "./data/restaurants.csv",method = "curl")
download.file(fileUrl,destfile = "./data/restaurants.csv")
download.file(fileUrl,destfile = "./data/restaurants.csv")
download.file(fileUrl,destfile = "./data/restaurants.csv",method = "curl")
setwd("F:/Coursera/datasciencecoursera/")
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile = "./data/restaurants.csv",method = "curl")
setwd("F:/Coursera/datasciencecoursera/R")
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile = "./data/restaurants.csv",method = "curl")
restData <- read.csv("./data/restaurants.csv")
head(restData,n=3)
tail(restData,n=3)
summary(restData)
str(restData)
quantile(restData$councilDistrict,na.rm = TRUE)
quantile(restData$councilDistrict,probs = c(0.5,0.75,0.9))
table(restData$zipCode,useNA = "ifany")
table(restData$councilDistrict,restData$zipCode)
sum(is.na(restData$councilDistrict))
any(is.na(restData$councilDistrict))
all(restData$zipCode>0)
colSums(is.na(restData))
all(colSums(is.na(restData))==0)
table(restData$zipCode %in% c("21212"))
table(restData$zipCode %in% c("21212","21213"))
restData[restData$zipCode %in% c("21212","21213"),]
data(UCBAdmissions)
DF = as.data.frame(UCBAdmissions)
summary(DF)
xt <- xtabs(Freq~Gender+Admit,data=DF)
xt
warpbreaks$replicate <- rep(1:9,len=54)
xt=xtabs(breaks~.data=warpbreaks)
xt=xtabs(breaks~.data=warpbreaks)
xt=xtabs(breaks~.,data=warpbreaks)
xt
View(warpbreaks)
ftable(xt)
fakeDate=rnorm(1e15)
fakeDate=rnorm(1e5)
object.size(fakeDate)
print(object.size(fakeDate),units = "Mb")
s1 <- seq(1,10,by=2);s1
s2 <- seq(1,10,length=3);s2
x <- c(1,3,8,25,100);seq(along=x)
restData$nearMe = restData$neighborhood %in% c("Roland Park","Homeland")
table(restData$nearMe)
restData$zipWrong=ifelse(restData$zipCode<0,TRUE,FALSE)
table(restData$zipWrong,restData$zipCode<0)
restData$zipGroups = cut(restData$zipCode,breaks = quantile(restData$zipCode))
table(restData$zipGroups)
table(restData$zipGroups,restData$zipCode)
library(Hmisc)
restData$zipGroups = cut2(restData$zipCode,g=4)
table(restData$zipGroups)
restData$zcf <- factor(restData$zipCode)
restData$zcf[1:10]
class(restData$zcf)
yesno <- sample(c("yes","no"),size = 10,replace = TRUE)
resnofac <- factor(yesno,levels = c("yes","no"))
relevel(yesnofac,ref = "yes")
resnofac <- factor(yesno,levels = c("yes","no"))
relevel(yesnofac,ref = "yes")
yesnofac <- factor(yesno,levels = c("yes","no"))
relevel(yesnofac,ref = "yes")
as.numeric(yesnofac)
library(Hmisc)
library(Hmisc);library(plyr)
restData2 = mutate(restData,zipGroups=cut2(zipCode,g=4))
table(restData2$zipGroups)
install.packages(c("car", "checkmate", "curl", "dplyr", "Formula", "git2r", "htmlwidgets", "httpuv", "Rcpp", "TTR", "xts"))
install.packages("curl")
if(!file.exists("./data")){dir.create("./data")}
fileUrl2 <- "https://dl.dropboxusercontent.com/u/7710864/data/solutions-apr29.csv"
fileUrl1 <- "https://dl.dropboxusercontent.com/u/7710864/data/reviews-apr29.csv"
download.file(fileUrl1,destfile = "./data/reviews.csv",method="curl")
library(devtools)
install_github("curl")
install_github("jeroen/curl")
library(devtools)
find_rtools()
install_github("jeroen/curl")
install_github("jeroen/curl")
install.packages("curl")
fileUrl1 <- "https://dl.dropboxusercontent.com/u/7710864/data/reviews-apr29.csv"
fileUrl2 <- "https://dl.dropboxusercontent.com/u/7710864/data/solutions-apr29.csv"
download.file(fileUrl1,destfile = "./data/reviews.csv",method="curl")
reviews=read.csv("./data/reviews.csv")
solutions <- read.csv("./data/solutions.csv")
head(reviews,2)
head(solutions,2)
names(reviews)
names(solutions)
mergeData <- merge(reviews,solutions,by.x="solution_id",by.y="id",all=TRUE)
head(mergeData)
intersect(names(solutions),names(reviews))
mergeData2  <- merge(revies,solutions,all=TRUE)
mergeData2  <- merge(reviews,solutions,all=TRUE)
df1=data.frame(id=sample(1:10),x=rnorm(10))
df2=data.frame(id=sample(1:10),y=rnorm(10))
arrange(join(df1,df2),id)
library(plyr)
arrange(join(df1,df2),id)
df3=data.frame(id=sample(1:10),z=rnorm(10))
dfList = list(df1,df2,df3)
join_all(dfList)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(url,destfile = "./data/Q1.csv")
Q1 <- read.csv(file="./data/Q1.csv")
head(Q1$ACR)
class(Q1$ACR)
l.id <- with(Q1,ACR==3 & AGS==6)
agricultureLogical <- with(Q1,ACR==3 & AGS==6)
which(agricultureLogical==TRUE)
install.packages("jpeg")
library(jpeg)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
jpeg(url,native=TRUE)
readjpeg(url,native=TRUE)
library(jpeg)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
readJPEG(url,native=TRUE)
url1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
readJPEG(url1,native=TRUE)
download.file(url1,destfile = "./data/q2.jpeg")
readJPEG(source = "./data/q2.jpeg",native=TRUE)
q2 <- readJPEG(source = "./data/q2.jpeg",native=TRUE)
readJPEG(source = "./data/q2.jpeg",native=TRUE)
x <- readJPEG(source = "./data/q2.jpeg",native=TRUE)
quantile(x[,1],probs = 0.3)
quantile(x[,1],probs = c(0.3,0.8))
quantile(x[,2],probs = c(0.3,0.8))
x[30,80]
x[30,]
quantile(x,probs = c(0.3,0.8))
x <- readJPEG(source = "./data/q2.jpeg",native=TRUE)
quantile(x,probs = c(0.3,0.8))
url1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(url1,destfile = "./data/q2.jpeg")
download.file(url1,destfile = "./data/q2.jpeg")
download.file(url1,destfile = "./data/q2.jpeg",mode = "wb")
x <- readJPEG(source = "./data/q2.jpeg",native=TRUE)
quantile(x,probs = c(0.3,0.8))
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(url,destfile = "./data/q3_GD.csv")
download.file(url,destfile = "./data/q3_GD.csv",method = "curl")
url2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(url2,destfile = "./data/q3_edu.vsc")
download.file(url2,destfile = "./data/q3_edu.vsc",method = "curl")
download.file(url2,destfile = "./data/q3_edu.vsc",method = "curl")
download.file(url2,destfile = "./data/q3_edu.csv",method = "curl")
download.file(url,destfile = "./data/q3_GD.csv",method = "curl")
download.file(url,destfile = "./data/q3_GD.csv")
download.file(url2,destfile = "./data/q3_edu.csv")
q3.GD <- read.csv(file = "./data/q3_GD.csv",skip = 6)
View(q3.GD)
q3.GD <- read.csv(file = "./data/q3_GD.csv")
View(q3.GD)
q3.GD <- read.csv(file = "./data/q3_GD.csv",allowEscapes = TRUE)
View(q3.GD)
View(q3.GD)
q3.GD <- read.csv(file = "./data/q3_GD.csv",skip=3,allowEscapes = TRUE)
View(q3.GD)
q3.GD <- read.csv(file = "./data/q3_GD.csv",skip=3,skipNul = TRUE)
View(q3.GD)
q3.GD <- read.csv(file = "./data/q3_GD.csv",skip=3,strip.white = TRUE)
View(q3.GD)
q3.GD <- read.csv(file = "./data/q3_GD.csv",skip=3,nrows = 232)
View(q3.GD)
q3.GD <- read.csv(file = "./data/q3_GD.csv",skip=3,nrows = 232,na.strings="..")
View(q3.GD)
names(q3.GD)[1] <- "Country"
View(q3.GD)
q3.GD <- q3.GD[,c("country","Ranking","Economy","US.dollars.")]
View(q3.GD)
q3.GD <- q3.GD[,c("Country","Ranking","Economy","US.dollars.")]
q3.edu <- read.csv(file="./data/q3_edu.csv")
View(q3.edu)
q3.GD <- read.csv(file = "./data/q3_GD.csv",skip=4,nrows = 232,na.strings="..")
View(q3.GD)
View(q3.GD)
download.file(url,destfile = "./data/q3_GDP.csv")
View(q3.GD)
q3.GDP <- read.csv(file = "./data/q3_GDP.csv",skip=4,nrows = 232,na.strings="..")
rm(q3.GD)
View(q3.GDP)
q3.GDP <- read.csv(file = "./data/q3_GDP.csv",skip=4,nrows = 231,na.strings="..")
library(plyr)
q3.GDP <- filter(q3.GDP,!is.na(Country))
names(q3.GD)[1] <- "Country"
names(q3.GDP)[1] <- "Country"
q3.GDP <- q3.GDP[,c("Country","Ranking","Economy","US.dollars.")]
View(q3.GDP)
q3.GDP <- read.csv(file = "./data/q3_GDP.csv",skip=3,nrows = 231,na.strings="..")
names(q3.GDP)[1] <- "Country"
q3.GDP <- q3.GDP[,c("Country","Ranking","Economy","US.dollars.")]
q3.GDP <- filter(q3.GDP,!is.na(Country))
View(q3.GDP)
q3.GDP <- filter(q3.GDP,!is.na("Country"))
q3.GDP <- read.csv(file = "./data/q3_GDP.csv",skip=3,nrows = 231,na.strings="..")
names(q3.GDP)[1] <- "Country"
q3.GDP <- q3.GDP[,c("Country","Ranking","Economy","US.dollars.")]
q3.GDP <- q3.GDP[!is.na(q3.GDP$Country),]
View(q3.GDP)
q3.GDP <- read.csv(file = "./data/q3_GDP.csv",skip=3,nrows = 231,na.strings=c(" ",".."))
names(q3.GDP)[1] <- "Country"
q3.GDP <- q3.GDP[,c("Country","Ranking","Economy","US.dollars.")]
View(q3.GDP)
q3.GDP <- q3.GDP[!is.na(q3.GDP$Country),]
q3.GDP <- read.csv(file = "./data/q3_GDP.csv",skip=3,nrows = 231,na.strings=c("",".."))
names(q3.GDP)[1] <- "Country"
q3.GDP <- q3.GDP[,c("Country","Ranking","Economy","US.dollars.")]
q3.GDP <- q3.GDP[!is.na(q3.GDP$Country),]
View(q3.GDP)
q3.GDP <- read.csv(file = "./data/q3_GDP.csv",skip=3,na.strings=c("",".."))
names(q3.GDP)[1] <- "Country"
q3.GDP <- q3.GDP[,c("Country","Ranking","Economy","US.dollars.")]
q3.GDP <- q3.GDP[!is.na(q3.GDP$Country),]
View(q3.GDP)
View(q3.edu)
View(q3.edu)
q3 <- merge(q3.edu,q3.GDP,by.x="CountryCode",by.y = "Country")
q3 <- merge(q3.edu,q3.GDP,by.x="CountryCode",by.y = "Country",all = TRUE)
View(q3)
arrange(q3,desc(CountryCode))
q3 <- arrange(q3,desc(CountryCode))
View(q3)
View(q3)
q3 <- arrange(q3,desc(Ranking))
View(q3)
q3.GDP <- q3.GDP[!is.na(q3.GDP$Ranking),]
q3.edu <- read.csv(file="./data/q3_edu.csv")
q3 <- merge(q3.edu,q3.GDP,by.x="CountryCode",by.y = "Country",all = TRUE)
q3 <- arrange(q3,desc(Ranking))
View(q3)
q3 <- merge(q3.edu,q3.GDP,by.x="CountryCode",by.y = "Country")
q3 <- arrange(q3,desc(Ranking))
View(q3)
class(q3$Ranking)
q3$Ranking <- as.numeric(as.character(q3$Ranking))
q3 <- arrange(q3,desc(Ranking))
View(q3)
View(q3)
with(q3[q3$Income.Group=="High income: OECD",],mean(Ranking))
with(q3[q3$Income.Group=="High income: nonOECD",],mean(Ranking))
q3$Range <- cut(q3$Ranking,breaks = 5)
levels(q3$Range)
q3$Range <- cut(q3$Ranking,breaks = 5,labels = FALSE)
levels(q3$Range)
head(q3$Range)
q3$Range <- cut(q3$Ranking,breaks = 5,labels = c("1","2","3","4","5"))
levels(q3$Range)
View(q3)
with(q3,table(Income.Group,Range))
View(q3)
View(q3)
library(swirl)
swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
library(tidyr)
View(students)
students
?gather
gather(students,sex,count,-grade)
students2
res <- gather(students2,sex_class,count,-grade)
View(res)
res
?separate
separate(res,sex_class,c("sex","class"))
submit()
students3
submit()
?spread
submit()
library(readr)
parse_number("class5")
submit()
View(students3)
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread( test, grade) %>%
print
submit()
students4
submit()
submit()
submit()
passed
failed
passed <- mutate(passed,status="passed")
failed <- mutate(failed,status="failed")
?bind_rows
bind_rows(passed,failed)
sat
submit()
submit()
